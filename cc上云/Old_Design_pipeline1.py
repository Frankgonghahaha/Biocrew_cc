#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import math
import json
import pandas as pd
import numpy as np
from itertools import combinations
# å¹¶è¡Œç›¸å…³
from joblib import Parallel, delayed
import multiprocessing

# ======== 1) åŸºæœ¬é…ç½®ï¼šä½ çš„æ•°æ®ç›®å½•ï¼ˆå¯æŒ‰éœ€ä¿®æ”¹ï¼‰ ========
BASE_DIR = "/Users/frank_gong/æ–‡æ¡£/ç”Ÿç‰©æ™ºèƒ½ä½“/20251015/ä¿¡æ¯è¡¨"
PATH_SHEET1 = os.path.join(BASE_DIR, "Sheet1_Complementarity.xlsx")
PATH_SHEET2 = os.path.join(BASE_DIR, "Sheet2_Species_environment.xlsx")
PATH_SHEET3 = os.path.join(BASE_DIR, "Sheet3_Function_enzyme_kact.xlsx")
PATH_SHEET4 = os.path.join(BASE_DIR, "Sheet4_species_enzyme.xlsx")
OUTPUT_PATH = os.path.join(BASE_DIR, "Result1_candidate_function_species.csv")

# PhyloMint æ–‡ä»¶è·¯å¾„ä¸åˆ—åï¼ˆå¦‚æœ‰ä¸åŒï¼Œå¯åœ¨æ­¤è°ƒæ•´ï¼‰
PATH_PHYLOMINT = os.path.join(BASE_DIR, "Sheet5_PhyloMint.csv")
PHYLO_COL_A = "A"
PHYLO_COL_B = "B"
PHYLO_COL_COMPETITION = "Competition"
PHYLO_COL_COMPLEMENTARITY = "Complementarity"
PHYLO_SUFFIX = "_CDS"  # functional/complement species â†’ PhyloMint çš„ ID åç¼€

# ======== 2) è¯»å–&æ¸…æ´—å·¥å…·å‡½æ•° ========
def read_first_sheet(path):
    """è¯» Excel ç¬¬ä¸€å¼ è¡¨ï¼›è‹¥ä¸å­˜åœ¨æŠ¥é”™æ›´æ¸…æ™°ã€‚"""
    if not os.path.exists(path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    x = pd.ExcelFile(path)
    return pd.read_excel(path, sheet_name=x.sheet_names[0])

def normalize_name(x):
    """ç»Ÿä¸€åç§°ï¼šå»ç©ºç™½ã€å…¨å°å†™ã€åŠè§’åŒ–ï¼ˆåªåšç®€å•å¤„ç†ï¼‰ã€‚"""
    if pd.isna(x):
        return None
    s = str(x).strip()
    s = s.replace("ï¼ˆ", "(").replace("ï¼‰", ")").replace("ï¼Œ", ",").replace("ã€", ",")
    s = " ".join(s.split())
    return s

def split_enzyme_list(s):
    """æŠŠ Sheet4 é‡Œçš„é…¶åˆ—è¡¨æ‹†åˆ†ï¼›æ”¯æŒâ€˜,â€™æˆ–â€˜ã€â€™ç­‰åˆ†éš”ã€‚"""
    if pd.isna(s) or str(s).strip() == "":
        return []
    s = str(s).replace("ã€", ",").replace("ï¼›", ",").replace(";", ",")
    parts = [p.strip() for p in s.split(",") if p.strip()]
    return parts


def to_float_safe(x):
    try:
        return float(x)
    except Exception:
        return np.nan

# ======== 2.1) è½¯ç¯å¢ƒè¯„åˆ†å·¥å…·å‡½æ•°ï¼ˆä¸‰è§’éš¶å± + æŒ‡æ•°å°¾éƒ¨ï¼‰ ========
import math

def _tri_or_tail(x, xmin, xopt, xmax, k=math.log(10)):
    """ä¸‰è§’éš¶å± + åŒºé—´å¤–æŒ‡æ•°å°¾éƒ¨ï¼›å…è®¸ xopt ç¼ºå¤±ã€‚è¿”å› [0,1] æˆ– Noneï¼ˆæ— æ³•è¯„åˆ†ï¼‰ã€‚"""
    try:
        import numpy as _np
    except Exception:  # å…œåº•ï¼Œé¿å…æœªå¯¼å…¥ numpy çš„é—®é¢˜
        _np = None
    def _isnan(v):
        try:
            return _np.isnan(v) if _np is not None else pd.isna(v)
        except Exception:
            return pd.isna(v)
    if xmin is None or xmax is None or _isnan(xmin) or _isnan(xmax):
        return None
    if x is None or _isnan(x):
        return None
    rng = xmax - xmin
    if rng <= 0:
        return None
    # åŒºé—´å†…ï¼šä¸‰è§’/æ¢¯å½¢
    if xmin <= x <= xmax:
        if (xopt is None) or _isnan(xopt) or not (xmin <= xopt <= xmax):
            center = (xmin + xmax) / 2.0
            half = max(rng / 2.0, 1e-9)
            return max(0.0, 1.0 - abs(x - center) / half)
        left = max(xopt - xmin, 1e-9)
        right = max(xmax - xopt, 1e-9)
        return max(0.0, 1.0 - abs(x - xopt) / max(left, right))
    # åŒºé—´å¤–ï¼šæŒ‡æ•°å°¾éƒ¨
    dist = xmin - x if x < xmin else x - xmax
    return math.exp(-k * (dist / max(rng, 1e-9)))


def _salt_soft(salt_star, salt_max, k=math.log(10)):
    """ç›åº¦è½¯è¯„åˆ†ï¼šæœªè¶…è¿‡ä¸Šé™å¾— 1ï¼›è¶…è¿‡ç”¨æŒ‡æ•°è¡°å‡ã€‚ç¼ºå€¼è¿”å› Noneã€‚"""
    if salt_max is None or pd.isna(salt_max) or salt_star is None or pd.isna(salt_star):
        return None
    if salt_star <= salt_max:
        return 1.0
    scale = max(1.0, salt_max)
    return math.exp(-k * ((salt_star - salt_max) / scale))


def _o2_soft(o2_value, o2_target):
    """æ°§ç¯å¢ƒè½¯è¯„åˆ†ï¼šåŒ¹é…=1.0ï¼›æœªçŸ¥/æ¨¡ç³Š=0.5ï¼›ä¸åŒ¹é…=0.2ã€‚"""
    val = str(o2_value).strip().lower() if pd.notna(o2_value) else ""
    tgt = str(o2_target or "").strip().lower()
    if val == tgt and val != "":
        return 1.0
    if val in {"", "unknown", "nan", "none"}:
        return 0.5
    return 0.2


def soft_env_score_row(row, T_star, pH_star, salt_star, o2_target,
                        wT=0.35, wPH=0.35, wS=0.10, wO2=0.20):
    """å¯¹å•è¡Œç¯å¢ƒæ•°æ®è®¡ç®—è½¯ç¯å¢ƒåˆ†ï¼Œè‡ªåŠ¨è·³è¿‡ç¼ºå¤±ç»´åº¦å¹¶é‡å½’ä¸€åŒ–ã€‚"""
    Tmin = row.get("temperature_minimum")
    Tmax = row.get("temperature_maximum")
    Top  = row.get("temperature_optimum_C")
    pHmin= row.get("ph_minimum")
    pHmax= row.get("ph_maximum")
    pHopt= row.get("ph_optimum")
    Smax = row.get("salinity_maximum")
    o2   = row.get("oxygen_tolerance")

    sT  = _tri_or_tail(T_star, Tmin, Top, Tmax)
    sPH = _tri_or_tail(pH_star, pHmin, pHopt, pHmax)
    sS  = _salt_soft(salt_star, Smax)
    sO2 = _o2_soft(o2, o2_target)

    parts, weights = [], []
    for sc, w in [(sT, wT), (sPH, wPH), (sS, wS), (sO2, wO2)]:
        if sc is not None:
            parts.append(sc * w)
            weights.append(w)
    if not parts:
        return 0.0
    return float(sum(parts) / sum(weights))

# ======== 3) æ‰“å°æç¤ºå¹¶æ”¶é›†ç›®æ ‡å·¥å†µ ========
print("è¯·è¾“å…¥ä½ çš„ç›®æ ‡å·¥å†µï¼ˆæŒ‰æç¤ºè¾“å…¥æ•°å€¼/é€‰é¡¹ï¼‰")
T_target = to_float_safe(input("ç›®æ ‡æ¸©åº¦ (Â°C)ï¼š").strip())
pH_target = to_float_safe(input("ç›®æ ‡ pHï¼š").strip())
sal_target = to_float_safe(input("ç›®æ ‡ç›åº¦ï¼ˆ% NaClï¼‰ï¼š").strip())
O2_text = normalize_name(input("æ°§ç¯å¢ƒï¼ˆå¥½æ°§ / åŒæ°§ / ç¼ºæ°§ï¼‰ï¼š").strip())

if any(np.isnan(v) for v in [T_target, pH_target, sal_target]):
    print("âŒ æ¸©åº¦ / pH / ç›åº¦ è¯·è¾“å…¥æ•°å­—ã€‚")
    sys.exit(1)

# æ°§ç¯å¢ƒæ˜ å°„ï¼šå¥½æ°§ -> tolerantï¼›åŒæ°§/ç¼ºæ°§ -> not tolerant
if O2_text in ["å¥½æ°§", "æœ‰æ°§", "aerobic", "æ°§æ°”", "æ°§åŒ–"]:
    O2_target = "tolerant"
elif O2_text in ["åŒæ°§", "ç¼ºæ°§", "å¾®æ°§", "anaerobic", "anoxic", "microaerobic", "ä½æ°§"]:
    O2_target = "not tolerant"
else:
    print("âš ï¸ æœªè¯†åˆ«çš„æ°§ç¯å¢ƒè¾“å…¥ï¼Œé»˜è®¤ä½¿ç”¨â€˜å¥½æ°§â€™ â†’ tolerant")
    O2_target = "tolerant"

print(f"\nâœ… ç›®æ ‡å·¥å†µï¼šT={T_target}Â°C, pH={pH_target}, ç›åº¦={sal_target}% NaCl, æ°§ç¯å¢ƒ={O2_text} â†’ æ˜ å°„ä¸º {O2_target}\n")

# ======== 4) è¯»å–å››å¼ è¡¨ ========
print("è¯»å–æ•°æ®è¡¨...")
# å›ºå®šå·¥ä½œè¡¨åï¼š
# Sheet1_Complementarity.xlsx -> Sheet1
# Sheet2_Species_environment.xlsx -> prediction
# Sheet3_Function_enzyme_kact.xlsx -> Sheet1
# Sheet4_species_enzyme.xlsx -> Sheet1

df_comp = pd.read_excel(PATH_SHEET1, sheet_name="Sheet1")
df_env  = pd.read_excel(PATH_SHEET2, sheet_name="prediction")
# â€”â€” å…¼å®¹ä¸åŒç¯å¢ƒè¡¨çš„ç‰©ç§æ ‡è¯†åˆ—å â€”â€” 
# æœŸæœ›å­˜åœ¨ â€œstrainâ€ åˆ—ï¼›è‹¥æ²¡æœ‰ï¼Œè‡ªåŠ¨ä»å¸¸è§å‘½åä¸­é€‰æ‹©å¹¶é‡å‘½åä¸º â€œstrainâ€
_strain_aliases = {
    "strain", "species", "Species"
}
if "strain" not in df_env.columns:
    candidates = [c for c in df_env.columns if str(c).strip() in _strain_aliases]
    if candidates:
        chosen = candidates[0]
        df_env = df_env.rename(columns={chosen: "strain"})
        print(f"âš ï¸ ç¯å¢ƒè¡¨æœªæ‰¾åˆ°åˆ— 'strain'ï¼Œå·²ä½¿ç”¨ '{chosen}' åˆ—ä½œä¸ºç‰©ç§æ ‡è¯†å¹¶é‡å‘½åä¸º 'strain'ã€‚")
    else:
        raise KeyError(f"ç¯å¢ƒè¡¨ç¼ºå°‘ç”¨äºç‰©ç§æ ‡è¯†çš„åˆ—ï¼ˆæœŸæœ› 'strain' æˆ–å¸¸è§åˆ«åï¼‰ã€‚å½“å‰åˆ—: {list(df_env.columns)}")
df_kcat = pd.read_excel(PATH_SHEET3, sheet_name="Sheet1")
df_map  = pd.read_excel(PATH_SHEET4, sheet_name="Sheet1")

# ======== 5) å›ºå®šåˆ—æ˜ å°„ï¼ˆæ•°æ®æ¥å…¥å±‚ï¼šç¡®å®šç‰ˆï¼‰ ========
# äº’è¡¥å…³ç³»ï¼ˆSheet1_Complementarity.xlsx / Sheet1ï¼‰
df_comp = df_comp.rename(columns={
    "Species": "functional_species",
    "Complementarity Species": "complement_species",
    "Competition": "competition_index",
    "Complementarity": "complementarity_index",
    "Delta": "delta_index",
})[[
    "functional_species",
    "complement_species",
    "competition_index",
    "complementarity_index",
    "delta_index",
]]

# è§„èŒƒåç§°ï¼Œä¿è¯ä¸ df_map["species"] ä¸€è‡´
df_comp["functional_species"] = df_comp["functional_species"].apply(normalize_name)
df_comp["complement_species"] = df_comp["complement_species"].apply(normalize_name)

# ç¯å¢ƒï¼ˆSheet2_Species_environment.xlsx / predictionï¼‰
# ç›´æ¥ä½¿ç”¨æ–‡ä»¶ä¸­çš„æ ‡å‡†åˆ—åï¼›è‹¥ç¼ºå°‘ salinity_optimum åˆ—åˆ™ä¸å¼ºåˆ¶
env_cols_expected = [
    "strain",
    "temperature_optimum_C",
    "temperature_minimum",
    "temperature_maximum",
    "ph_optimum",
    "ph_minimum",
    "ph_maximum",
    "salinity_optimum",
    "salinity_minimum",
    "salinity_maximum",
    "oxygen_tolerance",
]
existing_env_cols = [c for c in env_cols_expected if c in df_env.columns]
df_env_use = df_env[existing_env_cols].copy()

# ç±»å‹æ ‡å‡†åŒ–
df_env_use["oxygen_tolerance"] = (
    df_env_use["oxygen_tolerance"].astype(str).str.strip().str.lower()
)
for c in [
    "temperature_optimum_C",
    "temperature_minimum",
    "temperature_maximum",
    "ph_optimum",
    "ph_minimum",
    "ph_maximum",
    "salinity_optimum",
    "salinity_minimum",
    "salinity_maximum",
]:
    if c in df_env_use.columns:
        df_env_use[c] = pd.to_numeric(df_env_use[c], errors="coerce")

# ç‰©ç§-é…¶æ˜ å°„ï¼ˆSheet4_species_enzyme.xlsx / Sheet1ï¼‰
df_map = df_map.rename(columns={
    "Functional Species": "species",
    "Function Enzyme": "enzymes",
})[["species", "enzymes"]]

def split_enzyme_list_fixed(s):
    if pd.isna(s) or str(s).strip() == "":
        return []
    s = str(s).replace("ã€", ",").replace("ï¼›", ",").replace(";", ",")
    return [p.strip() for p in s.split(",") if p.strip()]

df_map["species"] = df_map["species"].apply(normalize_name)
df_map["enzymes_list"] = df_map["enzymes"].apply(split_enzyme_list_fixed)
df_map = df_map[["species", "enzymes_list"]].dropna(subset=["species"]).reset_index(drop=True)

# é…¶-Kcatï¼ˆSheet3_Function_enzyme_kact.xlsx / Sheet1ï¼‰
df_kcat = df_kcat.rename(columns={
    "Enzyme": "enzyme",
    "Kcat value (1/s)": "kcat",
})[["enzyme", "kcat"]]

df_kcat["_enzyme_norm"] = df_kcat["enzyme"].astype(str).str.strip().str.lower()
df_kcat["_kcat"] = pd.to_numeric(df_kcat["kcat"], errors="coerce")
kcat_map = df_kcat.groupby("_enzyme_norm")["_kcat"].median().to_dict()

# ======== 6) è®¡ç®—åŠŸèƒ½èŒçš„ Kcat_max / Kcat_mean ========
def enzyme_to_kcat(enzyme_name):
    if enzyme_name is None:
        return np.nan
    key = str(enzyme_name).strip().lower()
    return kcat_map.get(key, np.nan)

def species_kcat_stats(enz_list):
    vals = [enzyme_to_kcat(e) for e in (enz_list or [])]
    vals = [v for v in vals if not pd.isna(v)]
    if not vals:
        return np.nan, np.nan
    return float(np.max(vals)), float(np.mean(vals))

species_rec = []
for _, row in df_map.iterrows():
    s = row["species"]
    enz = row["enzymes_list"]
    kmax, kmean = species_kcat_stats(enz)
    species_rec.append({
        "species": s,
        "enzymes": ",".join(enz),
        "kcat_max": kmax,
        "kcat_mean": kmean,
    })
df_func = pd.DataFrame(species_rec)

# ======== 7) ç¯å¢ƒåŒ¹é…ï¼šæŒ‰ç›®æ ‡å·¥å†µç­›é€‰ ========
df_env_use["match_temp"] = True
if {"temperature_minimum", "temperature_maximum"}.issubset(df_env_use.columns):
    df_env_use["match_temp"] = (
        (df_env_use["temperature_minimum"] <= T_target)
        & (T_target <= df_env_use["temperature_maximum"])
    )

df_env_use["match_ph"] = True
if {"ph_minimum", "ph_maximum"}.issubset(df_env_use.columns):
    df_env_use["match_ph"] = (
        (df_env_use["ph_minimum"] <= pH_target)
        & (pH_target <= df_env_use["ph_maximum"])
    )

df_env_use["match_salt"] = True
if "salinity_maximum" in df_env_use.columns:
    df_env_use["match_salt"] = (
        (sal_target <= df_env_use["salinity_maximum"]) | df_env_use["salinity_maximum"].isna()
    )

# æ°§åŒ¹é…ï¼ˆå¥½æ°§ â†’ tolerantï¼›åŒæ°§/ç¼ºæ°§ â†’ not tolerantï¼‰
df_env_use["match_o2"] = (df_env_use["oxygen_tolerance"].str.lower() == O2_target)

# æ€»åŒ¹é…
df_env_use["env_match_all"] = df_env_use[["match_temp", "match_ph", "match_salt", "match_o2"]].all(axis=1)

# è½¯ç¯å¢ƒåŒ¹é…åˆ†ï¼ˆ0~1ï¼‰ï¼šåŸºäºç›®æ ‡å·¥å†µçš„è¿ç»­è¯„åˆ†
df_env_use["env_soft_score"] = df_env_use.apply(
    lambda r: soft_env_score_row(r, T_target, pH_target, sal_target, O2_target),
    axis=1
)

# ä¸ºäº’è¡¥èŒæ£€æµ‹å‡†å¤‡ï¼šæŒ‰ strain å»ºç«‹ç¯å¢ƒåŒ¹é…çš„æŸ¥æ‰¾è¡¨
_env_cols_needed = [
    "strain","env_match_all","env_soft_score","fail_reasons","match_o2","match_temp","match_ph","match_salt",
    "temperature_minimum","temperature_maximum","ph_minimum","ph_maximum","salinity_maximum","oxygen_tolerance"
]
cols_present = [c for c in _env_cols_needed if c in df_env_use.columns]
df_env_lookup = df_env_use[cols_present].copy()

# æ„å»ºå­—å…¸ï¼šstrain -> ç¯å¢ƒæ˜¯å¦é€šè¿‡ åŠ æ˜ç»†
def _reason_row(r):
    reasons = []
    if not r.get("match_o2", True):
        reasons.append("oxygen_mismatch")
    if not r.get("match_temp", True):
        reasons.append("temperature_out_of_range")
    if not r.get("match_ph", True):
        reasons.append("pH_out_of_range")
    if not r.get("match_salt", True):
        reasons.append("salinity_exceeds_max")
    return ";".join(reasons) if reasons else "ok"

df_env_lookup["fail_reasons"] = df_env_lookup.apply(_reason_row, axis=1)
_env_by_strain = {
    str(r["strain"]): {k: r.get(k) for k in ["env_match_all","fail_reasons","env_soft_score"]}
    for _, r in df_env_lookup.iterrows()
}

# ======== 8) åˆå¹¶åŠŸèƒ½ä¿¡æ¯ä¸ç¯å¢ƒè¡¨ ========
merged1 = df_func.merge(df_env_use, how="left", left_on="species", right_on="strain")

# ======== 9) è¾“å‡ºå€™é€‰ï¼šå…ˆçœ‹ç¯å¢ƒå®Œå…¨åŒ¹é…çš„åŠŸèƒ½èŒ ========
candidates = merged1[ merged1["env_match_all"] == True ].copy()

# æ’åºï¼šä¼˜å…ˆçœ‹ kcat_maxï¼ˆé™åºï¼‰ï¼Œå†çœ‹ kcat_mean
candidates = candidates.sort_values(by=["kcat_max","kcat_mean"], ascending=[False, False])

# é€‰æ‹©è¾“å‡ºåˆ—
out_cols = [
    "species", "enzymes", "kcat_max", "kcat_mean",
    "temperature_optimum_C","temperature_minimum","temperature_maximum",
    "ph_optimum","ph_minimum","ph_maximum",
    "salinity_optimum","salinity_minimum","salinity_maximum",
    "oxygen_tolerance"
]
out_cols = [c for c in out_cols if c in candidates.columns]
# === å¯¹æ¯ä¸ªå€™é€‰åŠŸèƒ½èŒï¼Œç»Ÿè®¡å…¶äº’è¡¥å¾®ç”Ÿç‰©åœ¨ç›®æ ‡å·¥å†µä¸‹çš„é€šè¿‡æƒ…å†µ ===
comp_stats = {"complement_total": [], "complement_pass": [], "complement_fail": [],
              "complement_pass_names": [], "complement_fail_names": []}

for _, crow in candidates.iterrows():
    func_name = crow.get("species")
    # æ‰¾åˆ°è¯¥åŠŸèƒ½èŒçš„æ‰€æœ‰äº’è¡¥èŒï¼ˆå»é‡ï¼‰
    comps = df_comp.loc[df_comp["functional_species"] == func_name, "complement_species"].dropna().astype(str).unique().tolist()
    total = len(comps)
    pass_list, fail_list = [], []
    for c in comps:
        info = _env_by_strain.get(c)
        if info is None:
            fail_list.append(f"{c} (no_env_record)")
        else:
            if bool(info.get("env_match_all", False)):
                pass_list.append(c)
            else:
                reason = info.get("fail_reasons", "fail")
                fail_list.append(f"{c} ({reason})")
    comp_stats["complement_total"].append(total)
    comp_stats["complement_pass"].append(len(pass_list))
    comp_stats["complement_fail"].append(len(fail_list))
    comp_stats["complement_pass_names"].append(";".join(pass_list))
    comp_stats["complement_fail_names"].append(";".join(fail_list))

# è¿½åŠ åˆ°è¾“å‡ºè¡¨
candidates_out = candidates[out_cols].reset_index(drop=True)
for k, v in comp_stats.items():
    candidates_out[k] = v

# ======== 10) æ‰“å°é¢„è§ˆ & ä¿å­˜ ========
print("\n===== æ»¡è¶³ç›®æ ‡å·¥å†µçš„â€˜åŠŸèƒ½èŒâ€™å€™é€‰ï¼ˆæŒ‰ kcat_max æ’åºï¼Œå‰ 10 æ¡ï¼‰=====")
print(candidates_out.head(10).to_string(index=False))

candidates_out.to_csv(OUTPUT_PATH, index=False, encoding="utf-8")
print(f"\nâœ… å·²ä¿å­˜å€™é€‰èŒæ¸…å•åˆ°ï¼š{OUTPUT_PATH}")

print("\n[æ ¸å¯¹] compåˆ—:", list(df_comp.columns))
print("[æ ¸å¯¹] env åˆ—:", list(df_env_use.columns))
print("[æ ¸å¯¹] kcatåˆ—:", list(df_kcat.columns))
print("[æ ¸å¯¹] map åˆ—:", list(df_map.columns))

print("\næç¤ºï¼š")
print("1) è¿™ä¸€æ­¥ä»…å®Œæˆâ€˜åŠŸèƒ½èŒâ€™åœ¨ç›®æ ‡å·¥å†µä¸‹çš„ç­›é€‰ä¸åŠŸèƒ½å¼ºåº¦æ±‡æ€»ï¼ˆKcatï¼‰ã€‚")
print("2) ä¸‹ä¸€æ­¥å¯æŠŠäº’è¡¥å¾®ç”Ÿç‰©ï¼ˆSheet1ï¼‰å¼•å…¥ï¼Œåšç»„åˆæ‰“åˆ†ä¸ç¾¤è½ä¼˜åŒ–ã€‚")
print("3) è‹¥ç¯å¢ƒè¡¨çš„ â€˜strainâ€™ åç§°ä¸ç‰©ç§è¡¨çš„ â€˜speciesâ€™ ä¸ä¸€è‡´ï¼Œéœ€è¦æä¾›ä¸€ä¸ªæ˜ å°„è¡¨åšæ›´å¼ºçš„å¯¹é½ã€‚")
# ======== 11) åŠŸèƒ½èŒ + äº’è¡¥èŒ æ‰“åˆ†æ¨¡å— (S_microbe) ========

print("\n===== å¯¹åŠŸèƒ½èŒå’Œäº’è¡¥èŒè¿›è¡Œç»¼åˆæ‰“åˆ† (S_microbe) =====")

# 1ï¸âƒ£ å…ˆå‡†å¤‡åŠŸèƒ½èŒè¡¨ï¼ˆå·²ç»åœ¨ candidates_out é‡Œï¼‰
func_records = []
for _, r in candidates_out.iterrows():
    # ä½¿ç”¨è½¯ç¯å¢ƒåˆ†ï¼šå€™é€‰åŠŸèƒ½èŒé€šå¸¸å·²åœ¨åŒºé—´å†…ï¼Œä½†è½¯åˆ†å¯åŒºåˆ†è¿œè¿‘
    _envrow = df_env_use.loc[df_env_use["strain"] == r["species"]]
    _envsoft = float(_envrow.iloc[0]["env_soft_score"]) if (not _envrow.empty and pd.notna(_envrow.iloc[0]["env_soft_score"])) else 1.0
    func_records.append({
        "species": r["species"],
        "kcat_max": r.get("kcat_max", np.nan),
        "kcat_mean": r.get("kcat_mean", np.nan),
        "enzyme_diversity": len(str(r.get("enzymes", "")).split(",")) if pd.notna(r.get("enzymes")) else 0,
        "environment_match": _envsoft,
        "source": "functional"
    })

# 2ï¸âƒ£ æ”¶é›†æ‰€æœ‰é€šè¿‡ç¯å¢ƒåŒ¹é…çš„äº’è¡¥èŒåå•
comp_pass_all = []
for names in candidates_out["complement_pass_names"]:
    if isinstance(names, str) and names.strip():
        comp_pass_all.extend([n.strip() for n in names.split(";") if n.strip()])
comp_pass_all = sorted(set(comp_pass_all))

print(f"å…±æ£€æµ‹åˆ° {len(comp_pass_all)} ä¸ªé€šè¿‡ç›®æ ‡å·¥å†µçš„äº’è¡¥èŒã€‚")

# 3ï¸âƒ£ äº’è¡¥èŒæ‰“åˆ†æ•°æ®æ”¶é›†
comp_records = []
for cname in comp_pass_all:
    # ç¯å¢ƒåŒ¹é…ä¿¡æ¯
    env_row = df_env_use.loc[df_env_use["strain"] == cname]
    if not env_row.empty and pd.notna(env_row.iloc[0].get("env_soft_score", np.nan)):
        env_score = float(env_row.iloc[0]["env_soft_score"])  # 0~1 è¿ç»­åˆ†
    else:
        env_score = 0.0  # ç¼ºå¤±åˆ™è§†ä¸ºä¸åŒ¹é…

    # é…¶ä¸ Kcat ä¿¡æ¯
    func_row = df_map.loc[df_map["species"] == cname]
    if func_row.empty:
        kmax, kmean, enz_list = np.nan, np.nan, []
    else:
        enz_list = func_row.iloc[0]["enzymes_list"]
        kmax, kmean = species_kcat_stats(enz_list)
    enz_div = len(enz_list)

    comp_records.append({
        "species": cname,
        "kcat_max": kmax,
        "kcat_mean": kmean,
        "enzyme_diversity": enz_div,
        "environment_match": env_score,
        "source": "complement"
    })

# 4ï¸âƒ£ åˆå¹¶åŠŸèƒ½èŒä¸äº’è¡¥èŒ
df_all = pd.DataFrame(func_records + comp_records)

# 5ï¸âƒ£ å½’ä¸€åŒ–å¹¶è®¡ç®— S_microbe
def normalize_01(series):
    if series.min() == series.max():
        return np.ones_like(series)
    return (series - series.min()) / (series.max() - series.min())

df_all["f_Kcat"] = normalize_01(df_all["kcat_max"].fillna(0))
df_all["f_EnvMatch"] = df_all["environment_match"].fillna(0)
df_all["f_EnzymeDiversity"] = normalize_01(df_all["enzyme_diversity"].fillna(0))

# æƒé‡
wK, wE, wD = 0.5, 0.4, 0.1
df_all["S_microbe"] = (
    wK * df_all["f_Kcat"]
    + wE * df_all["f_EnvMatch"]
    + wD * df_all["f_EnzymeDiversity"]
)

# 6ï¸âƒ£ æ’åºä¸è¾“å‡º
df_all = df_all.sort_values(by="S_microbe", ascending=False)
output_path = os.path.join(BASE_DIR, "Result2_candidate_scores.csv")
df_all.to_csv(output_path, index=False, encoding="utf-8")

print(f"\nâœ… å·²ä¿å­˜åŠŸèƒ½èŒ + äº’è¡¥èŒæ‰“åˆ†ç»“æœåˆ°: {output_path}")
print(df_all.head(10).to_string(index=False))

# ======== 12) ç”Ÿæˆ species é—´äº’è¡¥/ç«äº‰æŒ‡æ•°è¡¨ï¼ˆèåˆ Sheet1 ä¸ PhyloMintï¼‰ ========
print("\n===== åŸºäº Sheet1 ä¸ PhyloMint ç”Ÿæˆäº’ä½œçŸ©é˜µ =====")

# 12.1 æ„å»º species å…¨é›†ï¼ˆåŠŸèƒ½èŒ + é€šè¿‡ç¯å¢ƒåŒ¹é…çš„äº’è¡¥èŒï¼‰
species_all = sorted(pd.Series(df_all["species"].astype(str).tolist()).dropna().unique().tolist())
print(f"å°†ç”Ÿæˆ {len(species_all)} ä¸ªç‰©ç§çš„ä¸¤ä¸¤äº’ä½œã€‚")

# 12.2 å»ºç«‹â€œåŠŸèƒ½èŒ-å…¶å¯¹åº”äº’è¡¥èŒâ€çš„é›†åˆï¼ˆæ¥è‡ª Sheet1_Complementarity.xlsxï¼‰
corresponding_pairs_set = set(zip(
    df_comp["functional_species"].astype(str),
    df_comp["complement_species"].astype(str)
))

# 12.3 è¯»å– PhyloMint
if not os.path.exists(PATH_PHYLOMINT):
    print(f"âš ï¸ æœªæ‰¾åˆ° PhyloMint æ–‡ä»¶ï¼š{PATH_PHYLOMINT}ï¼Œä»…è¾“å‡º Sheet1 å†…å·²æœ‰é…å¯¹ã€‚")
    df_phy = pd.DataFrame(columns=[PHYLO_COL_A, PHYLO_COL_B, PHYLO_COL_COMPETITION, PHYLO_COL_COMPLEMENTARITY])
else:
    df_phy = pd.read_csv(PATH_PHYLOMINT)
    # æ ¡éªŒå¹¶æ ‡å‡†åŒ–
    for c in [PHYLO_COL_A, PHYLO_COL_B]:
        if c not in df_phy.columns:
            raise ValueError(f"PhyloMint ç¼ºå°‘åˆ—ï¼š{c}")
        df_phy[c] = df_phy[c].astype(str).str.strip()
    for c in [PHYLO_COL_COMPETITION, PHYLO_COL_COMPLEMENTARITY]:
        if c not in df_phy.columns:
            raise ValueError(f"PhyloMint ç¼ºå°‘åˆ—ï¼š{c}")
        df_phy[c] = pd.to_numeric(df_phy[c], errors="coerce")

# â€”â€” å°† PhyloMint é¢„èšåˆä¸ºæ— åºé”®å­—å…¸ï¼Œä¾¿äº O(1) æŸ¥æ‰¾ â€”â€”
if 'df_phy' in locals() and not df_phy.empty:
    df_phy["_A"] = df_phy[PHYLO_COL_A].astype(str).str.strip()
    df_phy["_B"] = df_phy[PHYLO_COL_B].astype(str).str.strip()
    _key_arr = np.where(df_phy["_A"] <= df_phy["_B"],
                        df_phy["_A"] + "||" + df_phy["_B"],
                        df_phy["_B"] + "||" + df_phy["_A"])
    df_phy["_key"] = _key_arr
    _phy_mean = (df_phy.groupby("_key", as_index=True)[[PHYLO_COL_COMPETITION, PHYLO_COL_COMPLEMENTARITY]].mean())
    phy_dict = _phy_mean.to_dict(orient="index")
else:
    phy_dict = {}

def _phylomint_pair_avg(a, b):
    """A=a_CDS,B=b_CDS ä¸ A=b_CDS,B=a_CDS çš„ Competition/Complementarity åˆå¹¶æ±‚å‡å€¼"""
    a_id = f"{a}{PHYLO_SUFFIX}"
    b_id = f"{b}{PHYLO_SUFFIX}"
    key = a_id + "||" + b_id if a_id <= b_id else b_id + "||" + a_id
    rec = phy_dict.get(key)
    if rec is None:
        return np.nan, np.nan, np.nan
    comp_mean = float(rec.get(PHYLO_COL_COMPETITION, np.nan))
    compl_mean = float(rec.get(PHYLO_COL_COMPLEMENTARITY, np.nan))
    delta = float(compl_mean - comp_mean) if (not pd.isna(comp_mean) and not pd.isna(compl_mean)) else np.nan
    return comp_mean, compl_mean, delta

# â€”â€” Sheet1 çš„åŠŸèƒ½â†”äº’è¡¥å…³ç³»é¢„æ„å»ºæˆå­—å…¸ï¼ˆæœ‰åºé”®ï¼‰â€”â€”
sheet1_dict = {
    (str(r["functional_species"]), str(r["complement_species"])): (
        float(r["competition_index"]),
        float(r["complementarity_index"]),
        float(r["delta_index"])
    )
    for _, r in df_comp.iterrows()
}

def _choose_sheet1_if_corresponding(a, b):
    """
    è‹¥ (a,b) æ˜¯â€œåŠŸèƒ½èŒ-å…¶å¯¹åº”äº’è¡¥èŒâ€çš„å…³ç³»ï¼ˆå‡ºç°åœ¨ Sheet1 ä¸­ï¼‰ï¼Œ
    åˆ™ç›´æ¥è¿”å› Sheet1 æ•°å€¼ï¼ˆæ³¨æ„ df_comp å·²æŒ‰å‡å€¼èšåˆ/æˆ–æŒ‰å•è¡Œä½¿ç”¨ï¼‰ã€‚
    """
    rec = sheet1_dict.get((a, b))
    if rec is not None:
        c, m, d = rec
        return c, m, d, True
    rec2 = sheet1_dict.get((b, a))
    if rec2 is not None:
        c, m, d = rec2
        return c, m, d, True
    return np.nan, np.nan, np.nan, False

# å¹¶è¡Œè®¡ç®—äº’ä½œçŸ©é˜µ
cpu_total = multiprocessing.cpu_count()
n_jobs = max(1, cpu_total - 1)
print(f"ğŸ’¡ å¹¶è¡Œè®¡ç®—äº’ä½œçŸ©é˜µï¼Œä½¿ç”¨ {n_jobs}/{cpu_total} ä¸ªCPUæ ¸å¿ƒ")

def _compute_pair_record(a, b):
    comp_mean, compl_mean, delta, used_sheet1 = _choose_sheet1_if_corresponding(a, b)
    source = "from_sheet1" if used_sheet1 else "from_phylomint"
    if not used_sheet1:
        comp_mean, compl_mean, delta = _phylomint_pair_avg(a, b)
    return {
        "functional_species": a,
        "complement_species": b,
        "competition_index": comp_mean,
        "complementarity_index": compl_mean,
        "delta_index": delta,
        "source": source
    }

interaction_records = Parallel(n_jobs=n_jobs, backend="loky", prefer="processes")(
    delayed(_compute_pair_record)(a, b) for a, b in combinations(species_all, 2)
)

df_interact = pd.DataFrame(interaction_records)

# 12.5 å¯¹ç§°è¡¥é½ï¼ˆä¾¿äºä»»æ„æ–¹å‘æ£€ç´¢ï¼‰
df_rev = df_interact.rename(columns={
    "functional_species": "complement_species",
    "complement_species": "functional_species"
})
df_all_pairs = pd.concat([df_interact, df_rev], ignore_index=True)
df_all_pairs = df_all_pairs.sort_values(by=["functional_species", "complement_species"]).reset_index(drop=True)

# 12.6 ä¿å­˜è¾“å‡º
merged_out_path = os.path.join(BASE_DIR, "Result3_pair_Com_index.csv")
df_all_pairs.to_csv(merged_out_path, index=False, encoding="utf-8")
print(f"âœ… å·²ç”Ÿæˆèåˆäº’ä½œçŸ©é˜µï¼š{merged_out_path}")

# 12.7 é¢„è§ˆ
print(df_all_pairs.head(12).to_string(index=False)) 